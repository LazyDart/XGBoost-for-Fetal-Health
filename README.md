# This is an Old Project from 2 years Ago. It does not represent my current skillset. However I keep it for sentimental reasons.

# XGBoost Fetal Health Classification

This project implements an XGBoost model for fetal health classification using the Fetal Health dataset available on [Kaggle](https://www.kaggle.com/datasets/andrewmvd/fetal-health-classification).

## Overview

The goal of this project is to predict fetal health based on various features using the XGBoost algorithm. The model achieves an accuracy of 94% on the test dataset.

## Project Structure

- **Notebook:** [XGBoost_Fetal_Health_Classification.ipynb](XGBoost_Fetal_Health_Classification.ipynb)
- **Model:** [XGB Fetal Health](XGB%20Fetal%20Health)
- **Requirements:** [requirements.txt](requirements.txt)

## Dependencies

- **matplotlib:** 3.7.1
- **numpy:** 1.23.5
- **pandas:** 2.0.0
- **scikit-learn:** 1.2.2
- **seaborn:** 0.13.1
- **xgboost:** 2.0.3

## How to Use

1. Clone the repository:

```bash
git clone https://github.com/LazyDart/XGBoost-for-Fetal-Health.git
cd XGBoost-Fetal-Health
```

2. Install the required dependencies:

```bash
pip install -r requirements.txt
```

3. Run the Jupyter Notebook:

```bash
jupyter notebook XGBoost_Fetal_Health_Classification.ipynb
```

4. Explore the notebook for detailed insights into data analysis, model training, and evaluation.

## Results

The trained XGBoost model achieves an accuracy of 94% on the test dataset. The feature importance analysis is presented in the notebook.

## Issues and Future Work

If you encounter any issues or have suggestions for improvement, please feel free to open an issue or submit a pull request. Future work may involve fine-tuning the model, exploring additional features, or optimizing hyperparameters.

## License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.